{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAndCheckOutput(test_inputs, correct_outputs, weight1, weight2, bias):\n",
    "    outputs = []\n",
    "    # Generate and check output\n",
    "    for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "        linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "        output = int(linear_combination >= 0)\n",
    "        is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "        outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "    # Print output\n",
    "    num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "    output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "    if not num_wrong:\n",
    "        print('Nice!  You got it all correct.\\n')\n",
    "    else:\n",
    "        print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "    print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AND-Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                  -2.0                    0          Yes\n",
      "      0          1                  -1.0                    0          Yes\n",
      "      1          0                  -1.0                    0          Yes\n",
      "      1          1                   0.0                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set weight1, weight2, and bias for AND-Perceptron\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -2.0\n",
    "\n",
    "# Inputs and outputs for AND-Perceptron\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "generateAndCheckOutput(test_inputs, correct_outputs, weight1, weight2, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR-Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                  -1.0                    0          Yes\n",
      "      0          1                   0.0                    1          Yes\n",
      "      1          0                   0.0                    1          Yes\n",
      "      1          1                   1.0                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set weight1, weight2, and bias for OR-Perceptron\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -1.0\n",
    "\n",
    "# Inputs and outputs for OR-Perceptron\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, True, True, True]\n",
    "generateAndCheckOutput(test_inputs, correct_outputs, weight1, weight2, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT-Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                   2.0                    1          Yes\n",
      "      0          1                  -1.0                    0          Yes\n",
      "      1          0                   2.0                    1          Yes\n",
      "      1          1                  -1.0                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set weight1, weight2, and bias for NOT-Perceptron\n",
    "weight1 = 0.0\n",
    "weight2 = -3.0\n",
    "bias = 2.0\n",
    "\n",
    "# Inputs and outputs for NOT-Perceptron\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "generateAndCheckOutput(test_inputs, correct_outputs, weight1, weight2, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But you know we don't have to manually fill weights using mathematical intuition each time as we did in above, we will take random weights and write an algorithm to make it optimal, reduce error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    if prediction(X, W, b) is 1 and y is 0:\n",
    "        print('-ve')\n",
    "    elif prediction(X, W, b) is 0 and y is 1:\n",
    "        print('+ve')\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.78051</td>\n",
       "      <td>-0.063669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.28774</td>\n",
       "      <td>0.291390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40714</td>\n",
       "      <td>0.178780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29230</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50922</td>\n",
       "      <td>0.352560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1  2\n",
       "0  0.78051 -0.063669  1\n",
       "1  0.28774  0.291390  1\n",
       "2  0.40714  0.178780  1\n",
       "3  0.29230  0.421700  1\n",
       "4  0.50922  0.352560  1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431])),\n",
       " (array([-34.39834701]), array([-85.03584431]))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPerceptronAlgorithm(data.iloc[:, :2], data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
